#!/usr/bin/env python3

import sys, copy, json, datetime
sys.path.insert(0, 'Resource')
sys.path.insert(0, 'Prism')
sys.path.insert(0, '../data')

import prism_compute as Computer
import prism_encode_adv as Encoder
import prism_extension_adv as Prism
import dataHandler as Data
from constant import *
from helper import *


# --- TRAIN ---
def processExtension(result, lastFrequent, lastItemIndex,
 lastSeqBlocks, lastOffsets, lastPosBlocks,
 seqBlocksList, posOffsetsList, posBlocksList, 
 items, isSeqExt):
	
	lengthOfItems = len(items)

	for itemIndex in range(lastItemIndex, lengthOfItems):
		curItem 							= items[itemIndex]
		seqBlockTarget 				= seqBlocksList[itemIndex]
		posOffsetsListTarget 	= posOffsetsList[itemIndex]
		posBlocksTarget 			= posBlocksList[itemIndex]

		(seqBlocksExt, posOffsetsExt, posBlocksExt) = Prism.extend(
			lastFrequent, curItem,
			lastSeqBlocks, seqBlockTarget,
			lastOffsets, posOffsetsListTarget,
			lastPosBlocks, posBlocksTarget,
			isSeqExt
		)

		supp = Computer.computeSupportOfPrimalValueArray(seqBlocksExt)
		
		if supp >= MIN_SUPP:
			if isSeqExt == True:
				lastFrequent += "->{0}".format(curItem)
			else:
				lastFrequent += ".{0}".format(curItem)

			# Ensure to make a copy instead of assign reference
			_lastSeqBlocks 	= copy.deepcopy(seqBlocksExt)
			_lastPosOffsets = copy.deepcopy(posOffsetsExt)
			_lastPosBlocks 	= copy.deepcopy(posBlocksExt)

			# Sequence extension
			processExtension(result, lastFrequent, 0,
				_lastSeqBlocks, _lastPosOffsets, _lastPosBlocks, 
				seqBlocksList, posOffsetsList, posBlocksList, 
				items, True)

			# Itemset extension
			processExtension(result, lastFrequent, itemIndex + 1, 
				_lastSeqBlocks, _lastPosOffsets, _lastPosBlocks, 
				seqBlocksList, posOffsetsList, posBlocksList, 
				items, False)

			result.append({
				"frequent": lastFrequent,
				"support": supp
			})
			print("~~> New frequent {0} has support {1}".format(lastFrequent, supp))

			numerOfCharsRemove = len(curItem)
			if isSeqExt == True:
				numerOfCharsRemove += 2
			else:
				numerOfCharsRemove += 1

			lastFrequent = lastFrequent[:-numerOfCharsRemove]

	return
 

def saveTrainedData(result, major):
	now = datetime.datetime.now()
	fileName = "Resource/{0}_{1}".format(major, now.isoformat())
	with open(fileName, "w") as fp:
		json.dump(result, fp, ensure_ascii=False, indent=2, sort_keys=True)

	return


def saveSortedSeq(seqs):
	now = datetime.datetime.now()
	SEQ_SORTED_DATA_PATH = "Resource/sortedSeq_{0}".format(now.isoformat())
	with open(SEQ_SORTED_DATA_PATH, "w") as fp:
		[fp.write("{0}\n".format(string(seq))) for seq in seqs]

	return


def train(major):
	# Sort and cache the data
	print("Loading data encoded from data/ ...")
	(sequences, items) = Data.loadData(major)
	items = sorted(items)
	sequences = [sortAdv(seq) for seq in sequences]
	saveSortedSeq(sequences)

	print("Encode all records ...")
	(primalBlocks, posOffsetList) = Encoder.processEncodePrimalBlockAllSequences(items, sequences)
	seqBlocks = Encoder.processEncodePrimalSeqAdv(items, sequences)

	numberOfItems = len(items)
	result = [] * numberOfItems

	print("Start training ...")
	for itemIndex in range(0, numberOfItems):
		print("-> Label {0} is processing ...".format(items[itemIndex]))

		seqBlockOfItem 			= seqBlocks[itemIndex]
		primalOffetsOfItem 	= posOffsetList[itemIndex]
		primalBlockOfItem 	= primalBlocks[itemIndex]

		processExtension(result, items[itemIndex], 0,
			seqBlockOfItem , primalOffetsOfItem, primalBlockOfItem, 
			seqBlocks, posOffsetList, primalBlocks,
			items, True
		)

		processExtension(result, items[itemIndex], itemIndex + 1,
			seqBlockOfItem, primalOffetsOfItem, primalBlockOfItem, 
			seqBlocks, posOffsetList, primalBlocks,
			items, False
		)
	
	for element in result:
		print("{0} - {1}".format(element["frequent"], element["support"]))
	
	saveTrainedData(result, major)
	return
# --- END TRAIN ---


# --- PREDICT ----
def loadTrainedData(filePath):
	with open(filePath) as fp:
		trainedData = json.load(fp)

	return trainedData


def predict(query, trainedDataPath):
	trainedData = loadTrainedData(trainedDataPath)

	for element in trainedData:
		isExist = True if element["frequent"].find(query) != -1 else False
		# FIXME: Improve the way to search
		if isExist:
			print("{0} - {1}".format(element["frequent"], element["support"]))

	return
# --- END PREDICT ---


# --- SHOW ----
def showTrained(filePath):
	trainedData = loadTrainedData(filePath)
	for item in trainedData:
		print(item)

	return
# --- END SHOW ---

def usage():
	print("./run")
	print("... train [ IT ]")
	print("... predict \"A.B->C\" <trainedDataPath>")
	print("... show [ IT ]")
	return


if __name__ == "__main__":
	
	numberOfFunc = 3
	argv = sys.argv

	if len(argv) < numberOfFunc:
		usage()
		exit(0)

	func = argv[1]

	if func == "train":
		major = argv[2].lower()
		train(major)

	elif func == "predict":
		query = argv[2]
		trainedDataPath = argv[3]
		predict(query, trainedDataPath)

	elif func == "show":
		filePath = argv[2]
		showTrained(filePath)

	else:
		usage()




