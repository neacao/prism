#!/usr/bin/env python3

import sys, copy, json, datetime, argparse
sys.path.insert(0, 'Resource')
sys.path.insert(0, 'Prism')
sys.path.insert(0, '../data')

import prism_compute as Computer
import prism_encode_adv as Encoder
import prism_extension_adv as Prism
import dataHandler as Data
from helper import *
from lookup_table import *

# Common setup
ap = argparse.ArgumentParser()
ap.add_argument("-f", "--func", required=False, help="function want to run")
ap.add_argument("-m", "--major", required=False, help="major want to train")
ap.add_argument("-q", "--query", required=False, help="the query want to predict")
ap.add_argument("-p", "--trainedPath", required=False, help="the trained data path")
args = vars(ap.parse_args())

# --- TRAIN ---
def processExtension(result,
 lastFrequent, lastItemIndex,
 lastSeqBlocks, lastOffsets, lastPosBlocks,
 seqBlocksList, posOffsetsList, posBlocksList, 
 items, isSeqExt):
	
	lengthOfItems = len(items)

	for itemIndex in range(lastItemIndex, lengthOfItems):
		curItem 							= items[itemIndex]
		seqBlockTarget 				= seqBlocksList[itemIndex]
		posOffsetsListTarget 	= posOffsetsList[itemIndex]
		posBlocksTarget 			= posBlocksList[itemIndex]

		(seqBlocksExt, posOffsetsExt, posBlocksExt) = Prism.extend(
			lastFrequent, curItem,
			lastSeqBlocks, seqBlockTarget,
			lastOffsets, posOffsetsListTarget,
			lastPosBlocks, posBlocksTarget,
			isSeqExt
		)

		supp = Computer.countSupportFromPrimalArray(seqBlocksExt)
		
		if supp >= MIN_SUPP:
			if isSeqExt == True:
				lastFrequent += "->{0}".format(curItem)
			else:
				lastFrequent += ".{0}".format(curItem)

			# Ensure to make a copy instead of assign reference
			_lastSeqBlocks 	= copy.deepcopy(seqBlocksExt)
			_lastPosOffsets = copy.deepcopy(posOffsetsExt)
			_lastPosBlocks 	= copy.deepcopy(posBlocksExt)

			# Sequence extension
			processExtension(result, lastFrequent, 0,
				_lastSeqBlocks, _lastPosOffsets, _lastPosBlocks, 
				seqBlocksList, posOffsetsList, posBlocksList, 
				items, True)

			# Itemset extension
			processExtension(result, lastFrequent, itemIndex + 1, 
				_lastSeqBlocks, _lastPosOffsets, _lastPosBlocks, 
				seqBlocksList, posOffsetsList, posBlocksList, 
				items, False)

			result.append({
				"frequent": lastFrequent,
				"support": supp
			})
			print("[x] New frequent {0} has support {1}".format(lastFrequent, supp))

			numerOfCharsRemove = len(curItem)
			numerOfCharsRemove += 2 if isSeqExt else 1 # len("->") = 2 - le len(".") = 1
			lastFrequent = lastFrequent[:-numerOfCharsRemove]
	return


def saveTrainedData(result, major):
	now = datetime.datetime.now()
	fileName = "Resource/{0}_trained_{1}".format(major, now.isoformat())
	with open(fileName, "w") as fp:
		json.dump(result, fp, ensure_ascii=False, indent=2, sort_keys=True)
	return


def saveSortedSeq(major, seqs):
	now = datetime.datetime.now()
	SEQ_SORTED_DATA_PATH = "Resource/{0}_encodeSorted_{1}".format(major, now.isoformat())
	with open(SEQ_SORTED_DATA_PATH, "w") as fp:
		[fp.write("{0}\n".format(string(seq))) for seq in seqs]
	return


def train(major):
	# Sort and cache the data
	print("> Loading data encoded from data/ ...")
	(sequences, items) = Data.loadData(major)
	items = sorted(items)
	sequences = [sortAdv(seq) for seq in sequences]
	saveSortedSeq(major, sequences)

	print("> Encode all records ...")
	(primalBlocks, posOffsetList) = Encoder.encodePrimalItemsetsAdv(items, sequences)
	seqBlocks = Encoder.encodePrimalSeqsAdv(items, sequences)

	numberOfItems = len(items)
	result = []

	print("> Start training ...")
	for itemIndex in range(0, numberOfItems):
		seqBlockOfItem 			= seqBlocks[itemIndex]
		primalOffetsOfItem 	= posOffsetList[itemIndex]
		primalBlockOfItem 	= primalBlocks[itemIndex]

		print("-> Label {0} is processing ...".format(items[itemIndex]))
		print("\tseqBlock: {0}\n\tprimalOffset: {1}\n\tprimalBlocks: {2}".format(seqBlockOfItem, "", ""))

		processExtension(result, items[itemIndex], 0,
			seqBlockOfItem , primalOffetsOfItem, primalBlockOfItem, 
			seqBlocks, posOffsetList, primalBlocks,
			items, True
		)

		processExtension(result, items[itemIndex], itemIndex + 1,
			seqBlockOfItem, primalOffetsOfItem, primalBlockOfItem, 
			seqBlocks, posOffsetList, primalBlocks,
			items, False
		)
	
	for element in result:
		print("{0} - {1}".format(element["frequent"], element["support"]))
	
	saveTrainedData(result, major)
	return
# --- END TRAIN ---


# --- PREDICT ----
def loadTrainedData(filePath):
	with open(filePath) as fp:
		trainedData = json.load(fp)
	return trainedData


def predict(query, trainedDataPath):
	trainedDataList = loadTrainedData(trainedDataPath)

	# Split based on sequence
	queryComponents = query.split("->")
	queryComponentsLength = len(queryComponents)

	for trainedData in trainedDataList:
		trainedDataComponenets = trainedData["frequent"].split("->")
		trainedDataComponenetsLength = len(trainedDataComponenets)
		idxQuery = 0

		for item in trainedDataComponenets:
			idxQuery += 1 if string(item).findAdv(queryComponents[idxQuery]) != -1 else -idxQuery

			if idxQuery == queryComponentsLength:
				print("{0} - {1}".format(trainedData["frequent"], trainedData["support"]))
	return
# --- END PREDICT ---


# --- SHOW ----
def showTrained(filePath):
	trainedData = loadTrainedData(filePath)
	[print(item) for item in trainedData]
	return
# --- END SHOW ---

def usage():
	print("./run")
	print("... -f train -m <major>")
	print("... -f predict -q \"<query> -p <trained data path>\"")
	print("... -f show -p <trained data path>")
	exit(0)


def parseParam(args):
	func = args["func"]

	if func == "train":
		if not args["major"]:
			usage()
			
		train(args["major"])

	elif func == "predict":
		if not args["query"] or not args["trainedPath"]:
			usage()

		predict(args["query"], args["trainedPath"])

	elif func == "show":
		if not args["trainedPath"]:
			usage()

		showTrained(args["trainedPath"])

	else:
		usage()


if __name__ == "__main__":
	parseParam(args)
	




