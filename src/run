#!/usr/bin/env python3

import sys, copy, json, datetime, argparse
sys.path.insert(0, 'Resource')
sys.path.insert(0, 'Prism')
sys.path.insert(0, 'Util')


import prism_compute as Computer
import prism_encode_adv as Encoder
import prism_extension_adv as Prism
import dataHandler as Data
from helper import *
from lookup_table import *


# Common setup
ap = argparse.ArgumentParser()
ap.add_argument("-f", "--func", required = True, help = "function want to run")
ap.add_argument("-m", "--major", required = False, help = "major want to train")
ap.add_argument("-q", "--query", required = False, help = "the raw query want to predict")
ap.add_argument("-q2", "--queryEncoded", required = False, help = "the query encoded want to predict")
ap.add_argument("-p", "--trainedPath", required = False, help = "the trained data path")
ap.add_argument("-c", "--configurePath", required = False, help = "configure data files path")
args = vars(ap.parse_args())


# --- TRAIN ---
def processExtension(result,
 lastFrequent, lastItemIndex,
 lastSeqBlocks, lastOffsets, lastPosBlocks,
 seqBlocksList, posOffsetsList, posBlocksList, 
 items, isSeqExt):
	
	lengthOfItems = len(items)

	for itemIndex in range(lastItemIndex, lengthOfItems):
		curItem 							= items[itemIndex]
		seqBlockTarget 				= seqBlocksList[itemIndex]
		posOffsetsListTarget 	= posOffsetsList[itemIndex]
		posBlocksTarget 			= posBlocksList[itemIndex]

		(seqBlocksExt, posOffsetsExt, posBlocksExt) = Prism.extend(
			lastFrequent, curItem,
			lastSeqBlocks, seqBlockTarget,
			lastOffsets, posOffsetsListTarget,
			lastPosBlocks, posBlocksTarget,
			isSeqExt
		)

		supp = Computer.countSupportFromPrimalArray(seqBlocksExt)
		
		if supp < MIN_SUPP: 
			continue

		if isSeqExt == True:
			lastFrequent += "->{0}".format(curItem)
			numerOfCharsRemove = 2
		else:
			lastFrequent += ".{0}".format(curItem)
			numerOfCharsRemove = 1

		# Ensure to make a copy instead of assign reference
		_lastSeqBlocks 	= copy.deepcopy(seqBlocksExt)
		_lastPosOffsets = copy.deepcopy(posOffsetsExt)
		_lastPosBlocks 	= copy.deepcopy(posBlocksExt)

		# Sequence extension
		processExtension(result, lastFrequent, 0,
			_lastSeqBlocks, _lastPosOffsets, _lastPosBlocks, 
			seqBlocksList, posOffsetsList, posBlocksList, 
			items, True)

		# Itemset extension
		processExtension(result, lastFrequent, itemIndex + 1, 
			_lastSeqBlocks, _lastPosOffsets, _lastPosBlocks, 
			seqBlocksList, posOffsetsList, posBlocksList, 
			items, False)

		result.append({
			"frequent": lastFrequent,
			"support": supp
		})
		print("[x] New frequent {0} has support {1}".format(lastFrequent, supp))

		numerOfCharsRemove += len(curItem)
		lastFrequent = lastFrequent[:-numerOfCharsRemove]
			
	return


def saveTrainedData(result, major):
	now = datetime.datetime.now()
	fileName = "Resource/{0}_trained_{1}".format(major, now.isoformat())
	with open(fileName, "w") as fp:
		json.dump(result, fp, ensure_ascii=False, indent=2, sort_keys=True)
	return


def saveSortedSeq(major, seqs):
	now = datetime.datetime.now()
	SEQ_SORTED_DATA_PATH = "Resource/{0}_encodeSorted_{1}".format(major, now.isoformat())
	with open(SEQ_SORTED_DATA_PATH, "w") as fp:
		[fp.write("{0}\n".format(string(seq))) for seq in seqs]
	return


def train(major, configurePath):
	print("> Loading data encoded from data/ ...")

	with open(configurePath) as fp:
		conf = json.load(fp)
	recordEncodedPath = conf["RECORD_ENCODED_PATH"]
	labelEncodedPath 	= conf["LABEL_ENCODED_PATH"]

	(sequences, items) = Data.loadData(recordEncodedPath, labelEncodedPath)
	items = sorted(items)
	sequences = [sortAdv(seq) for seq in sequences]
	saveSortedSeq(major, sequences)

	print("> Encode all records ...")
	(primalBlocks, posOffsetList) = Encoder.encodePrimalItemsetsAdv(items, sequences)
	seqBlocks = Encoder.encodePrimalSeqsAdv(items, sequences)

	numberOfItems = len(items)
	result = []

	print("> Start training ...")
	for itemIndex in range(0, numberOfItems):
		seqBlockOfItem 			= seqBlocks[itemIndex]
		primalOffetsOfItem 	= posOffsetList[itemIndex]
		primalBlockOfItem 	= primalBlocks[itemIndex]

		print("-> Label {0} is processing ...".format(items[itemIndex]))

		processExtension(result, items[itemIndex], 0,
			seqBlockOfItem , primalOffetsOfItem, primalBlockOfItem, 
			seqBlocks, posOffsetList, primalBlocks,
			items, True
		)

		processExtension(result, items[itemIndex], itemIndex + 1,
			seqBlockOfItem, primalOffetsOfItem, primalBlockOfItem, 
			seqBlocks, posOffsetList, primalBlocks,
			items, False
		)

	print("> Training done")
	# for element in result:
	# 	print("{0} - {1}".format(element["frequent"], element["support"]))
	
	saveTrainedData(result, major)
	return
# --- END TRAIN ---


# --- PREDICT ----
def loadTrainedData(filePath):
	with open(filePath) as fp:
		trainedData = json.load(fp)
	return trainedData


def searchItemset(itemset, itemsetTarget):
	idx = 0
	itemsetComponents = itemset.split(".")
	length = len(itemsetComponents)

	for idx in range(0, length):
		curItem = itemsetComponents[idx]
		if string(itemsetTarget).findAdv(curItem) == -1:
			return False

	return True


def predict(query, queryEncoded, trainedDataPath, configurePath):
	if queryEncoded:
		_queryEncoded = queryEncoded
	else:
		with open(configurePath) as fp:
			conf = json.load(fp)
		labelMappingPath 	= conf["LABEL_MAPPING_PATH"]
		_queryEncoded 		= Encoder.encodeQuery(query, labelMappingPath)
	
	trainedDataList 	= loadTrainedData(trainedDataPath)

	# Split based on sequence
	itemsetQueryComponents 				= _queryEncoded.split("->")
	itemsetQueryComponentsLength 	= len(itemsetQueryComponents)

	for trainedData in trainedDataList:
		trainedItemsetComponents 				= trainedData["frequent"].split("->")
		idxQuery = 0

		for itemset in trainedItemsetComponents:
			itemsetQuery = itemsetQueryComponents[idxQuery]
			idxQuery += 1 if searchItemset(itemsetQuery, itemset) else -idxQuery

			if idxQuery == itemsetQueryComponentsLength:
				print("{0} - {1}".format(trainedData["frequent"], trainedData["support"]))
				break

	return
# --- END PREDICT ---


# --- SHOW ----
def showTrained(filePath):
	trainedData = loadTrainedData(filePath)
	[print(item) for item in trainedData]
	return
# --- END SHOW ---


def usage():
	print("./run")
	print("... -f train -m <major> -c <configure file path>" )
	print("... -f predict -q \"<query>\" -c <configure file path> -p <trained data path>")
	print("... -f show -p <trained data path>")
	exit(0)


def parseParam(args):
	func = args["func"]

	if func == "train":
		major 				= args["major"] if "major" in args else None
		configurePath	= args["configurePath"] if "configurePath" in args else None
		
		if major == None or configurePath == None:
			usage()
			
		train(major, configurePath)

	elif func == "predict":
		query 				= args["query"] 				if "query" in args 					else None
		queryEncoded	= args["queryEncoded"] 	if "queryEncoded" in args 	else None
		trainedPath 	= args["trainedPath"]		if "trainedPath" in args 		else None
		configurePath = args["configurePath"] if "configurePath" in args 	else None

		if (query == None and queryEncoded == None) or (trainedPath == None or configurePath == None):
			usage()

		predict(query, queryEncoded, trainedPath,  configurePath)

	elif func == "show":
		trainedPath = args["trainedPath"] if "trainedPath" in args else None
		if trainedPath == None:
			usage()

		showTrained(trainedPath)

	else:
		usage()


if __name__ == "__main__":
	parseParam(args)
	




